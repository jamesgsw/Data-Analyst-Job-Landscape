{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology:\n",
    "* [1. Importing Relevant Libraries](#point_1)\n",
    "* [2. Preliminary Data Cleaning](#point_2)\n",
    "   * [2.1 Combining the different job title datasets](#point_2_1)\n",
    "   * [2.2 Checking Null Values](#point_2_2)\n",
    "   * [2.3 Data Transformation for Null Values](#point_2_3)\n",
    "   * [2.4 Handling the different permutation of Job Titles](#point_2_4)\n",
    "   * [2.5 Cleaning the company text entries](#point_2_5)\n",
    "   * [2.6 Sorting through description to get Technical Skills](#point_2_6)\n",
    "   * [2.7 Sorting through description to get Academic Skills](#point_2_7)\n",
    "   * [2.8 Education Level](#point_2_8)\n",
    "   * [2.9 Grouping Headquarters by Country](#point_2_9)\n",
    "   * [2.95 Cleaning Company Name](#point_2_9_5)\n",
    "   * [2.99 Send Clean dataframe to excel file for data analysis](#point_2_9_9)\n",
    "* [3. Salary Information](#point_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_1\"></a>\n",
    "# 1. Importing Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data Science Packages\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"Data Visualisation Packages\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_2\"></a>\n",
    "# 2. Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_2_1\"></a>\n",
    "## 2.1 Combining the different job title datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/Users/James/Documents/GitHub/Data-Analyst-Job-Landscape/Job Titles CSV Files/Glassdoor Data Scientist Jobs.csv')\n",
    "df2 = pd.read_csv('/Users/James/Documents/GitHub/Data-Analyst-Job-Landscape/Job Titles CSV Files/Glassdoor Data Engineer Jobs.csv')\n",
    "df3 = pd.read_csv('/Users/James/Documents/GitHub/Data-Analyst-Job-Landscape/Job Titles CSV Files/Glassdoor Data Analyst Jobs.csv')\n",
    "df4 = pd.read_csv('/Users/James/Documents/GitHub/Data-Analyst-Job-Landscape/Job Titles CSV Files/Glassdoor Business Intelligence Analyst Jobs.csv')\n",
    "df5 = pd.read_csv('/Users/James/Documents/GitHub/Data-Analyst-Job-Landscape/Job Titles CSV Files/Glassdoor Quantitative Analyst Jobs.csv')\n",
    "df6 = pd.read_csv('/Users/James/Documents/GitHub/Data-Analyst-Job-Landscape/Job Titles CSV Files/Glassdoor Technology Consultant Jobs.csv')\n",
    "df7 = pd.read_csv('/Users/James/Documents/GitHub/Data-Analyst-Job-Landscape/Job Titles CSV Files/Glassdoor Machine Learning Engineer Jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>We are looking for Data Scientists who are int...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>GovTech\\n3.6</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore, Singapore</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>2016</td>\n",
       "      <td>Government</td>\n",
       "      <td>Government Agencies</td>\n",
       "      <td>Government</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Location:\\nSingapore\\n\\nGeography:\\nAsia Pacif...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Boston Consulting Group\\n4.3</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>10000+ employees</td>\n",
       "      <td>1963</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>$10 to $25 million (SGD)</td>\n",
       "      <td>McKinsey &amp; Company, Bain &amp; Company, Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Scientist - Customer Experience Group</td>\n",
       "      <td>Data Scientist\\n\\nSingapore\\n\\nDell provides t...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Dell Technologies\\n4.1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Round Rock, TX</td>\n",
       "      <td>10000+ employees</td>\n",
       "      <td>1984</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>IT Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$10+ billion (SGD)</td>\n",
       "      <td>IBM, Apple, HP Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sr. Data Scientist Smart Home</td>\n",
       "      <td>The Dash Replenishment Service (DRS) is an inn...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Amazon\\n4.1</td>\n",
       "      <td>Singapore, SG</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>10000+ employees</td>\n",
       "      <td>1994</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$10+ billion (SGD)</td>\n",
       "      <td>Google, Microsoft, Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Analytics\\nData Scientist - QuantumBlack\\n\\nSi...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>QuantumBlack\\n4.1</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>501 to 1000 employees</td>\n",
       "      <td>2009</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>Palantir Technologies, Google, Microsoft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   Job Title  \\\n",
       "0           0                              Data Scientist   \n",
       "1           1                              Data Scientist   \n",
       "2           2  Data Scientist - Customer Experience Group   \n",
       "3           3               Sr. Data Scientist Smart Home   \n",
       "4           4                              Data Scientist   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  We are looking for Data Scientists who are int...     3.6   \n",
       "1  Location:\\nSingapore\\n\\nGeography:\\nAsia Pacif...     4.3   \n",
       "2  Data Scientist\\n\\nSingapore\\n\\nDell provides t...     4.1   \n",
       "3  The Dash Replenishment Service (DRS) is an inn...     4.1   \n",
       "4  Analytics\\nData Scientist - QuantumBlack\\n\\nSi...     4.1   \n",
       "\n",
       "                   Company Name       Location            Headquarters  \\\n",
       "0                  GovTech\\n3.6      Singapore    Singapore, Singapore   \n",
       "1  Boston Consulting Group\\n4.3      Singapore              Boston, MA   \n",
       "2        Dell Technologies\\n4.1      Singapore          Round Rock, TX   \n",
       "3                   Amazon\\n4.1  Singapore, SG             Seattle, WA   \n",
       "4             QuantumBlack\\n4.1      Singapore  London, United Kingdom   \n",
       "\n",
       "                     Size  Founded  Type of ownership             Industry  \\\n",
       "0  1001 to 5000 employees     2016         Government  Government Agencies   \n",
       "1        10000+ employees     1963  Company - Private           Consulting   \n",
       "2        10000+ employees     1984   Company - Public          IT Services   \n",
       "3        10000+ employees     1994   Company - Public             Internet   \n",
       "4   501 to 1000 employees     2009  Company - Private           Consulting   \n",
       "\n",
       "                   Sector                   Revenue  \\\n",
       "0              Government  Unknown / Non-Applicable   \n",
       "1       Business Services  $10 to $25 million (SGD)   \n",
       "2  Information Technology        $10+ billion (SGD)   \n",
       "3  Information Technology        $10+ billion (SGD)   \n",
       "4       Business Services  Unknown / Non-Applicable   \n",
       "\n",
       "                                     Competitors  \n",
       "0                                             -1  \n",
       "1  McKinsey & Company, Bain & Company, Accenture  \n",
       "2                            IBM, Apple, HP Inc.  \n",
       "3                     Google, Microsoft, Walmart  \n",
       "4       Palantir Technologies, Google, Microsoft  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5,df6, df7], axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_2_2\"></a>\n",
    "## 2.2 Checking Null Values\n",
    "The Null Values as we defined in the Data Collection notebook will be of value -1. Therefore, we would like to identify the number of rows that has the value of -1, indicating null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Job Title', 'Job Description', 'Rating', 'Company Name',\n",
      "       'Location', 'Headquarters', 'Size', 'Founded', 'Type of ownership',\n",
      "       'Industry', 'Sector', 'Revenue', 'Competitors'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "column_names = df.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 has 0 empty rows\n",
      "Job Title has 0 empty rows\n",
      "Job Description has 0 empty rows\n",
      "Rating has 0 empty rows\n",
      "Company Name has 0 empty rows\n",
      "Location has 0 empty rows\n",
      "Headquarters has 757 empty rows\n",
      "Size has 752 empty rows\n",
      "Founded has 1615 empty rows\n",
      "Type of ownership has 752 empty rows\n",
      "Industry has 1494 empty rows\n",
      "Sector has 1495 empty rows\n",
      "Revenue has 753 empty rows\n",
      "Competitors has 3185 empty rows\n"
     ]
    }
   ],
   "source": [
    "for that_column in column_names:\n",
    "    \n",
    "    seriesObj = df[that_column].apply(lambda x: str(x) == \"-1\")\n",
    "    numOfRows = len(seriesObj[seriesObj == True].index)\n",
    "    print(that_column + \" has \" + str(numOfRows) + \" empty rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings:** We realise that there are empty rows in Headquarters, Size, Founded, Type of Ownership, Industry, Type of ownership, industry, sector, revenue and Competitors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_2_3\"></a>\n",
    "## 2.3 Data Transformation for Null Values\n",
    "After we determine the columns that has the null values, we'll subsequently decide how do we handle this null values. We first need to calculate some statistics to determine if we should fill it in with pre-determined values or remove these columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Removing Unecessary Columns\n",
    "We realise that there are certain columns that has a high number of missing values, where some are more than half of dataset, and there's no meaningful value that we can fill in that would be realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Competitors','Location','Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_2_4\"></a>\n",
    "## 2.4 Handling the different permutation of Job Titles\n",
    "Now that we have handled the null values, we need to ensure that the number of job titles is managed. Companies have different naming structure and style for their job titles and would include various nuances to reflect the specificity of the job. However, this would make the sorting of the job title difficult, therefore we would need to create an algorithm that takes the spits out the job title that we have listed here:\n",
    "<br> Job Title:  ['Data Scientist', 'Data Scientist', 'Data Engineer', 'Data Engineer', 'Data Analyst', 'Data Analyst', 'Quantitative Analyst', 'Technology Consultant', 'Technology Consultant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying the Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "na                           2351\n",
       "Data Scientist                925\n",
       "Data Analyst                  477\n",
       "Data Engineer                 440\n",
       "Manager                       129\n",
       "Machine Learning Engineer      61\n",
       "Director                       17\n",
       "Name: Job Title, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def title_simplifier(title):\n",
    "    if 'data scientist' in title.lower():\n",
    "        return 'Data Scientist'\n",
    "    elif 'data engineer' in title.lower():\n",
    "        return 'Data Engineer'\n",
    "    elif 'data analyst' in title.lower():\n",
    "        return 'Data Analyst'\n",
    "    elif 'technology analyst' in title.lower():\n",
    "        return 'Technology Analyst'\n",
    "    elif 'machine learning' in title.lower():\n",
    "        return 'Machine Learning Engineer'\n",
    "    elif 'manager' in title.lower():\n",
    "        return 'Manager'\n",
    "    elif 'director' in title.lower():\n",
    "        return 'Director'\n",
    "    else:\n",
    "        return 'na'\n",
    "    \n",
    "#Title Simplifier\n",
    "df['Job Title'] = df['Job Title'].apply(title_simplifier)\n",
    "df['Job Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings:** We realise that there's a large number of results that do not fit our search parameters and do not have our keywords inside, therefore we'll drop these rows to improve the relevance and accuracy of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Scientist               925\n",
       "Data Analyst                 477\n",
       "Data Engineer                440\n",
       "Manager                      129\n",
       "Machine Learning Engineer     61\n",
       "Director                      17\n",
       "Name: Job Title, dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We drop the roles that do not fit our search keyword parameters\n",
    "df = df[df['Job Title'] != 'na']\n",
    "df['Job Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 'na' rows are dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying the seniority level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seniority(title):\n",
    "    if 'sr' in title.lower() or 'senior' in title.lower() or 'sr' in title.lower() or 'lead' in title.lower() or 'principal' in title.lower():\n",
    "            return 'Senior'\n",
    "    else:\n",
    "        return 'Junior'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Junior    2049\n",
       "Name: Seniority, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Seniority Simplifier\n",
    "df['Seniority'] = df['Job Title'].apply(seniority)\n",
    "df['Seniority'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_2_5\"></a>\n",
    "## 2.5 Cleaning the company text entries\n",
    "We realised that the company entries have the break line code('/n'), however we do not want that in our text file, therefore we apply a function to remove the break line code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Job Description'] = df['Job Description'].apply(lambda x: x.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_2_6\"></a>\n",
    "## 2.6 Sorting through description to get Technical Skills\n",
    "Often times, companies have a set of technical skills that they desire in their staff such as Python, AWS and Spark. Therefore, we shall search through the description and identify these skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AWS\n",
    "def get_technical_skills_aws(x):\n",
    "    x1 = str(x)\n",
    "    if \"aws\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['AWS'] = df['Job Description'].apply(get_technical_skills_aws)\n",
    "\n",
    "#Excel\n",
    "def get_technical_skills_excel(x):\n",
    "    x1 = str(x)\n",
    "    if \"excel\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['Excel'] = df['Job Description'].apply(get_technical_skills_excel)\n",
    "\n",
    "#Python\n",
    "def get_technical_skills_python(x):\n",
    "    x1 = str(x)\n",
    "    if \"python\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['Python'] = df['Job Description'].apply(get_technical_skills_python)\n",
    "\n",
    "#R\n",
    "def get_technical_skills_r(x):\n",
    "    x1 = str(x)\n",
    "    if \" r \" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['R'] = df['Job Description'].apply(get_technical_skills_r)\n",
    "\n",
    "#Spark\n",
    "def get_technical_skills_spark(x):\n",
    "    x1 = str(x)\n",
    "    if \"spark\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['Spark'] = df['Job Description'].apply(get_technical_skills_spark)\n",
    "\n",
    "#Hadoop\n",
    "def get_technical_skills_hadoop(x):\n",
    "    x1 = str(x)\n",
    "    if \"hadoop\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['Hadoop'] = df['Job Description'].apply(get_technical_skills_hadoop)\n",
    "\n",
    "#Scala\n",
    "def get_technical_skills_scala(x):\n",
    "    x1 = str(x)\n",
    "    if \"scala\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['Scala'] = df['Job Description'].apply(get_technical_skills_scala)\n",
    "\n",
    "#SQL\n",
    "def get_technical_skills_sql(x):\n",
    "    x1 = str(x)\n",
    "    if \"sql\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['SQL'] = df['Job Description'].apply(get_technical_skills_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_2_7\"></a>\n",
    "## 2.7 Sorting through description to get Academic Skills\n",
    "Often times, companies have a set of Academic skills that they desire in their staff such as Statistics and Machine Learning. Therefore, we shall search through the description and identify these skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multivariate Calculus\n",
    "def get_technical_skills_calculus(x):\n",
    "    x1 = str(x)\n",
    "    if \"calculus\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['Calculus'] = df['Job Description'].apply(get_technical_skills_calculus)\n",
    "\n",
    "#Database Management\n",
    "def get_technical_skills_database(x):\n",
    "    x1 = str(x)\n",
    "    if \"database management\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['Database Management'] = df['Job Description'].apply(get_technical_skills_database)\n",
    "\n",
    "#Machine Learning\n",
    "def get_technical_skills_ml(x):\n",
    "    x1 = str(x)\n",
    "    if \"machine learning\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['Machine Learning'] = df['Job Description'].apply(get_technical_skills_ml)\n",
    "\n",
    "#Statistics\n",
    "def get_technical_skills_stats(x):\n",
    "    x1 = str(x)\n",
    "    if \"stats\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['Statistics'] = df['Job Description'].apply(get_technical_skills_stats)\n",
    "\n",
    "#DevOps\n",
    "def get_technical_skills_devops(x):\n",
    "    x1 = str(x)\n",
    "    if \"devops\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['DevOps'] = df['Job Description'].apply(get_technical_skills_devops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_2_8\"></a>\n",
    "## 2.8 Education Level\n",
    "Education level is another important indicator that employers look for in hires. Therefore, we also want to investigate what level of education is expected from these individuals. We search 3 levels of education level: Bachelors Degreee, Masters and PhD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bachelors Degree\n",
    "def get_bachelors(x):\n",
    "    x1 = str(x)\n",
    "    if \"bachelors\" in x1.lower() or \"degree\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['Bachelors Degreee'] = df['Job Description'].apply(get_bachelors)\n",
    "\n",
    "#Masters\n",
    "def get_masters(x):\n",
    "    x1 = str(x)\n",
    "    if \"masters\" in x1.lower() or \"postgrad\" in x1.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['Masters'] = df['Job Description'].apply(get_masters)\n",
    "\n",
    "#PhD\n",
    "def get_phd(x):\n",
    "    x1 = str(x)\n",
    "    x2 = x1.strip(\".\")\n",
    "    if \"phd\" in x2.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['PhD'] = df['Job Description'].apply(get_phd)\n",
    "\n",
    "#PhD\n",
    "def get_no_education(x):\n",
    "    x1 = str(x)\n",
    "    x2 = x1.strip(\".\")\n",
    "    if \"phd\" in x2.lower() or \"masters\" in x2.lower() or \"postgrad\" in x2.lower() or \"bachelors\" in x2.lower() or \"degree\" in x2.lower():\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "df['No Education Specified'] = df['Job Description'].apply(get_phd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_2_9\"></a>\n",
    "## 2.9 Grouping Headquarters by Country\n",
    "There are many permutations of naming the company headquarters, therefore we create a function to handle this different permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Headquarters'] = df['Headquarters'].apply(lambda x: x.split(\",\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Headquarters'] = df['Headquarters'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_america(x):\n",
    "    if len(x) == 2:\n",
    "        return \"United States\"\n",
    "    else:\n",
    "        return x\n",
    "df['Headquarters'] = df['Headquarters'].apply(for_america)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Headquarters'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_2_9_5\"></a>\n",
    "## 2.95 Cleaning Company Name\n",
    "There's rating in the comapny name for some rows, therefore we wuld like to clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Company Name'] = df['Company Name'].apply(lambda x: x.split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_2_9_9\"></a>\n",
    "## 2.99 Send Clean dataframe to excel file for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('/Users/James/Documents/GitHub/Data-Analyst-Job-Landscape/Job Titles CSV Files/Job_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"point_3\"></a>\n",
    "## 3. Salary Information\n",
    "The salary information that we obtained has been cleaned and visualized on the Glassdoor salary section. Therefore, we have manually pulled the data out of the website, with the different position levels, pay, number of respondents and the number of listed jobs for that particular position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = {'Job Title':  ['Data Scientist', 'Data Scientist', 'Data Engineer', 'Data Engineer', 'Data Analyst', 'Data Analyst','Technology Consultant', 'Technology Consultant', 'Quantitative Analyst', 'Machine Learning Engineer'],\n",
    "               'Position Level': ['Senior', 'Junior', 'Senior', 'Junior', 'Senior', 'Junior','Senior', 'Junior', 'Junior', 'Junior'],\n",
    "               'Average Base Pay': [118000, 52200, 78000, 48000, 57600, 51800, 84000, 75600, 120000, 68400],\n",
    "               'Number of Respondents': [4, 3, 4, 1, 12, 33, 1, 9, 9, 8],\n",
    "               'Number of Listed Jobs': [928, 568, 1051, 4334, 923, 252, 821, 1902, 512, 723]\n",
    "               }\n",
    "\n",
    "salary_df = pd.DataFrame(salary_data, columns=[\n",
    "                         'Job Title', 'Position Level', 'Average Base Pay', 'Number of Respondents', 'Number of Listed Jobs'])\n",
    "salary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending the salary dataframe into an excel file to be used\n",
    "salary_df.to_excel('/Users/James/Documents/GitHub/Data-Analyst-Job-Landscape/Job Titles CSV Files/Salary by title.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
